# RTEMS ML Framework

> ì „ëµ íŒ¨í„´(Strategy Pattern)ê³¼ ë¹Œë” íŒ¨í„´(Builder Pattern)ì„ í™œìš©í•œ ëª¨ë¸ ë…ë¦½ì  ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

RTEMS(Real-Time Executive for Multiprocessor Systems) í™˜ê²½ì—ì„œì˜ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬ë¡œë“œ ë¶„ì„ ë° ì„±ëŠ¥ ì˜ˆì¸¡ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

- **ë¶„ë¥˜ & íšŒê·€ ì§€ì›**: Classificationê³¼ Regression ì‘ì—…ì„ ëª¨ë‘ ì§€ì›
- **ëª¨ë¸ ë…ë¦½ì **: ì–´ë–¤ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë„ ì‰½ê²Œ í†µí•© ê°€ëŠ¥
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ì „ì²˜ë¦¬ê¸°, ëª¨ë¸, íŠœë„ˆë¥¼ ê°„ë‹¨íˆ ì¶”ê°€
- **ìœ ì—°í•œ êµ¬ì„±**: Fluent Interfaceë¥¼ í†µí•œ ì§ê´€ì ì¸ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
- **íƒ€ì… ì•ˆì •ì„±**: Protocol ê¸°ë°˜ì˜ íƒ€ì… ì²´í‚¹
- **ëª¨ë¸ ì €ì¥/ë¡œë“œ**: PyTorch ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
- **ì¬ì‚¬ìš©ì„±**: ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë° ì¬ì‚¬ìš© ê°€ëŠ¥

## ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**ì£¼ìš” ì˜ì¡´ì„±:**
- `scikit-learn` - ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë° ì „ì²˜ë¦¬
- `torch` - ë”¥ëŸ¬ë‹ ëª¨ë¸ (NeuralNetworkRegressor, VGGRegressor)
- `xgboost` - Gradient Boosting ëª¨ë¸
- `pandas`, `numpy` - ë°ì´í„° ì²˜ë¦¬
- `matplotlib` - ì‹œê°í™”

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ë¶„ë¥˜ (Classification) ì˜ˆì œ

```python
from ml_framework import (
    MLPipelineBuilder,
    PipelineConfig,
    TaskType,
    CsvDataLoader,
    StandardScalerPreprocessor,
    RandomForestClassifier
)

# ì„¤ì • ì •ì˜
config = PipelineConfig(
    data_source="data/train.csv",
    train_test_split=0.2,
    random_state=42,
    task_type=TaskType.CLASSIFICATION  # ë¶„ë¥˜ ì‘ì—…
)

# íŒŒì´í”„ë¼ì¸ êµ¬ì„±
pipeline = (
    MLPipelineBuilder(config)
    .with_data_loader(CsvDataLoader())
    .with_preprocessing(StandardScalerPreprocessor())
    .with_model(RandomForestClassifier(n_estimators=100))
    .build()
)

# ì‹¤í–‰
results = pipeline.run()
print(f"Accuracy: {results['accuracy']:.4f}")
```

### íšŒê·€ (Regression) ì˜ˆì œ

```python
from ml_framework import (
    MLPipelineBuilder,
    PipelineConfig,
    TaskType,
    MemoryPatternRegressionDataLoader,
    MemoryPatternPaddingPreprocessor,
    NeuralNetworkRegressor
)

config = PipelineConfig(
    data_source="data/memory_pattern_large.json",
    train_test_split=0.2,
    random_state=42,
    task_type=TaskType.REGRESSION  # íšŒê·€ ì‘ì—…
)

pipeline = (
    MLPipelineBuilder(config)
    .with_data_loader(MemoryPatternRegressionDataLoader())
    .with_preprocessing(
        MemoryPatternPaddingPreprocessor(padding_value=-999.0)
    )
    .with_model(
        NeuralNetworkRegressor(
            hidden_layers=[256, 128, 64, 32],
            activation='relu',
            output_dim=6,  # 6ê°œì˜ íƒ€ê²Ÿ ë³€ìˆ˜
            learning_rate=0.001,
            epochs=300,
            batch_size=16
        )
    )
    .build()
)

results = pipeline.run()
print(f"RMSE: {results['rmse']:.4f}")
print(f"RÂ²: {results['r2']:.4f}")
```

### ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ

```python
from ml_framework import NeuralNetworkRegressor

# 1. ëª¨ë¸ í•™ìŠµ ë° ì €ì¥
model = NeuralNetworkRegressor(hidden_layers=[128, 64], output_dim=6)
model.fit(X_train, y_train)
model.save("checkpoint.pth")

# 2. ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
loaded_model = NeuralNetworkRegressor.from_checkpoint("checkpoint.pth")
predictions = loaded_model.predict(X_test)
```

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

```python
from ml_framework import (
    XGBoostClassifier,
    GridSearchTuner
)

pipeline = (
    MLPipelineBuilder(config)
    .with_data_loader(CsvDataLoader())
    .with_preprocessing(StandardScalerPreprocessor())
    .with_model(XGBoostClassifier())
    .with_tuner(
        GridSearchTuner(cv=5, scoring='f1'),
        param_grid={
            'n_estimators': [100, 200, 300],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    )
    .build()
)

results = pipeline.run()
print(f"Best parameters: {results.get('best_params')}")
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
rtems-ml-framework/
â”œâ”€â”€ ml_framework/
â”‚   â”œâ”€â”€ __init__.py          # íŒ¨í‚¤ì§€ ì§„ì…ì 
â”‚   â”œâ”€â”€ protocols.py         # Protocol ì¸í„°í˜ì´ìŠ¤ ì •ì˜
â”‚   â”œâ”€â”€ config.py            # ì„¤ì • í´ë˜ìŠ¤ (PipelineConfig, TaskType)
â”‚   â”œâ”€â”€ pipeline.py          # íŒŒì´í”„ë¼ì¸ í•µì‹¬ ë¡œì§
â”‚   â”œâ”€â”€ builder.py           # ë¹Œë” íŒ¨í„´ êµ¬í˜„
â”‚   â”œâ”€â”€ loaders.py           # ë°ì´í„° ë¡œë” êµ¬í˜„
â”‚   â”œâ”€â”€ preprocessors.py     # ì „ì²˜ë¦¬ê¸° êµ¬í˜„
â”‚   â”œâ”€â”€ models.py            # ëª¨ë¸ êµ¬í˜„
â”‚   â””â”€â”€ tuners.py            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë„ˆ êµ¬í˜„
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py                          # ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ
â”‚   â”œâ”€â”€ rtems_scheduling_classification.py      # RTEMS ìŠ¤ì¼€ì¤„ë§ ë¶„ë¥˜
â”‚   â”œâ”€â”€ memory_pattern_regression.py            # ë©”ëª¨ë¦¬ íŒ¨í„´ íšŒê·€ (MLPipelineBuilder)
â”‚   â”œâ”€â”€ memory_pattern_regression_standalone.py # ë©”ëª¨ë¦¬ íŒ¨í„´ íšŒê·€ (Standalone)
â”‚   â”œâ”€â”€ regression_pipeline_example.py          # íšŒê·€ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ
â”‚   â”œâ”€â”€ model_save_load_example.py              # ëª¨ë¸ ì €ì¥/ë¡œë“œ ì˜ˆì œ
â”‚   â””â”€â”€ vgg_regression_comparison.py            # VGG vs ì¼ë°˜ ë„¤íŠ¸ì›Œí¬ ë¹„êµ
â”‚
â”œâ”€â”€ data/                    # ë°ì´í„°ì…‹
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### 1. ë°ì´í„° ë¡œë” (Data Loaders)
- `CsvDataLoader` - CSV íŒŒì¼ ë¡œë“œ
- `JsonDataLoader` - JSON íŒŒì¼ ë¡œë“œ
- `RtemsJsonDataLoader` - RTEMS ì „ìš© JSON ë°ì´í„° ë¡œë“œ
- `MemoryPatternRegressionDataLoader` - ë©”ëª¨ë¦¬ íŒ¨í„´ íšŒê·€ ë°ì´í„° ë¡œë“œ

#### 2. ì „ì²˜ë¦¬ê¸° (Preprocessors)
- `StandardScalerPreprocessor` - í‘œì¤€í™” (í‰ê·  0, ë¶„ì‚° 1)
- `MinMaxScalerPreprocessor` - Min-Max ì •ê·œí™”
- `RobustScalerPreprocessor` - ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ë§
- `RtemsFeatureEngineeringPreprocessor` - RTEMS íŠ¹ì„± ê³µí•™
- `MemoryPatternPaddingPreprocessor` - ê°€ë³€ ê¸¸ì´ ë©”ëª¨ë¦¬ íŒ¨í„´ íŒ¨ë”©

#### 3. ëª¨ë¸ (Models)

**ë¶„ë¥˜ ëª¨ë¸:**
- `RandomForestClassifier` - ëœë¤ í¬ë ˆìŠ¤íŠ¸
- `XGBoostClassifier` - XGBoost

**íšŒê·€ ëª¨ë¸:**
- `NeuralNetworkRegressor` - PyTorch ê¸°ë°˜ ë‹¤ì¸µ ì‹ ê²½ë§ (ëª¨ë¸ ì €ì¥/ë¡œë“œ ì§€ì›)
- `VGGRegressor` - VGG-style ê¹Šì€ ì‹ ê²½ë§ (BatchNorm, Dropout í¬í•¨)

#### 4. íŠœë„ˆ (Tuners)
- `GridSearchTuner` - ê·¸ë¦¬ë“œ ì„œì¹˜
- `RandomSearchTuner` - ëœë¤ ì„œì¹˜
- `BayesianOptimizationTuner` - ë² ì´ì§€ì•ˆ ìµœì í™”

### ë””ìì¸ íŒ¨í„´

#### Strategy Pattern
ê° ì»´í¬ë„ŒíŠ¸(ë°ì´í„° ë¡œë”, ì „ì²˜ë¦¬ê¸°, ëª¨ë¸, íŠœë„ˆ)ë¥¼ ë…ë¦½ì ì¸ ì „ëµìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ëŸ°íƒ€ì„ì— êµì²´ ê°€ëŠ¥

```python
# ì „ëµì„ ì‰½ê²Œ êµì²´
pipeline.with_model(RandomForestClassifier())  # ì „ëµ 1
pipeline.with_model(XGBoostClassifier())       # ì „ëµ 2
pipeline.with_model(NeuralNetworkRegressor())  # ì „ëµ 3
```

#### Builder Pattern
ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ì„ ë‹¨ê³„ë³„ë¡œ êµ¬ì„±í•˜ì—¬ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ

```python
pipeline = (
    MLPipelineBuilder(config)
    .with_data_loader(...)
    .with_preprocessing(...)
    .with_model(...)
    .build()
)
```

## ğŸ”§ í™•ì¥í•˜ê¸°

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€

Protocolì„ êµ¬í˜„í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from loguru import logger
from typing import Any

class MyCustomRegressor:
    """ì»¤ìŠ¤í…€ íšŒê·€ ëª¨ë¸"""

    def __init__(self, **kwargs):
        self.params = kwargs
        self._is_fitted = False
        logger.info(f"Initializing MyCustomRegressor with params: {self.params}")

    def fit(self, X: Any, y: Any) -> "MyCustomRegressor":
        logger.info("Training MyCustomRegressor model")
        # í•™ìŠµ ë¡œì§ êµ¬í˜„
        self._is_fitted = True
        return self

    def predict(self, X: Any) -> Any:
        if not self._is_fitted:
            raise RuntimeError("Model must be fitted before prediction")
        logger.info("Predicting with MyCustomRegressor")
        # ì˜ˆì¸¡ ë¡œì§ êµ¬í˜„
        return predictions

    def save(self, path: str):
        """ëª¨ë¸ ì €ì¥ (ì„ íƒì‚¬í•­)"""
        pass

    @classmethod
    def from_checkpoint(cls, path: str) -> "MyCustomRegressor":
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ (ì„ íƒì‚¬í•­)"""
        pass
```

### ìƒˆë¡œìš´ ì „ì²˜ë¦¬ê¸° ì¶”ê°€

```python
from loguru import logger
from typing import Any

class MyCustomPreprocessor:
    """ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ê¸°"""

    def __init__(self):
        self._is_fitted = False

    def fit(self, data: Any) -> "MyCustomPreprocessor":
        logger.info("Fitting MyCustomPreprocessor")
        # fit ë¡œì§ êµ¬í˜„
        self._is_fitted = True
        return self

    def transform(self, data: Any) -> Any:
        if not self._is_fitted:
            raise RuntimeError("Preprocessor must be fitted before transform")
        logger.info("Transforming with MyCustomPreprocessor")
        # transform ë¡œì§ êµ¬í˜„
        return transformed_data

    def fit_transform(self, data: Any) -> Any:
        return self.fit(data).transform(data)
```

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì œ ì‹¤í–‰

```bash
# ê¸°ë³¸ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸
python examples/basic_usage.py

# RTEMS ìŠ¤ì¼€ì¤„ë§ ë¶„ë¥˜
python examples/rtems_scheduling_classification.py

# ë©”ëª¨ë¦¬ íŒ¨í„´ íšŒê·€ (MLPipelineBuilder ì‚¬ìš©)
python examples/memory_pattern_regression.py

# ë©”ëª¨ë¦¬ íŒ¨í„´ íšŒê·€ (Standalone)
python examples/memory_pattern_regression_standalone.py

# íšŒê·€ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ
python examples/regression_pipeline_example.py

# ëª¨ë¸ ì €ì¥/ë¡œë“œ ì˜ˆì œ
python examples/model_save_load_example.py

# VGG vs ì¼ë°˜ ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ ë¹„êµ
python examples/vgg_regression_comparison.py
```

## ğŸ“Š TaskType ì„¤ì •

í”„ë ˆì„ì›Œí¬ëŠ” ë‘ ê°€ì§€ ì‘ì—… íƒ€ì…ì„ ì§€ì›í•©ë‹ˆë‹¤:

### Classification (ë¶„ë¥˜)
- íƒ€ê²Ÿ: `label` ì»¬ëŸ¼
- í‰ê°€ ë©”íŠ¸ë¦­: Accuracy, F1-Score, Confusion Matrix
- Train/Test ë¶„í•  ì‹œ stratify ì ìš©

```python
config = PipelineConfig(
    data_source="data.csv",
    task_type=TaskType.CLASSIFICATION
)
```

### Regression (íšŒê·€)
- íƒ€ê²Ÿ: `target_*` ì»¬ëŸ¼ ë˜ëŠ” `config.target_columns` ì§€ì •
- í‰ê°€ ë©”íŠ¸ë¦­: RMSE, MAE, RÂ²
- ë‹¤ì¤‘ ì¶œë ¥ íšŒê·€ ì§€ì› (íƒ€ê²Ÿë³„ ë©”íŠ¸ë¦­ ê³„ì‚°)

```python
config = PipelineConfig(
    data_source="data.csv",
    task_type=TaskType.REGRESSION,
    target_columns=['target_1', 'target_2']  # ì„ íƒì‚¬í•­
)
```

## ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥

### 1. ë‹¤ì¤‘ ì „ì²˜ë¦¬ ë‹¨ê³„

```python
pipeline = (
    MLPipelineBuilder(config)
    .with_preprocessing(
        RobustScalerPreprocessor(),
        MinMaxScalerPreprocessor(feature_range=(0, 1))
    )
    .with_model(RandomForestClassifier())
    .build()
)
```

### 2. ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬

```python
# í•™ìŠµ ì¤‘ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
model = NeuralNetworkRegressor(...)
model.fit(X_train, y_train)
model.save("best_model.pth")

# ë‚˜ì¤‘ì— ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡
model = NeuralNetworkRegressor.from_checkpoint("best_model.pth")
predictions = model.predict(X_new)
```

### 3. ê°€ë³€ ê¸¸ì´ ë°ì´í„° ì²˜ë¦¬

ë©”ëª¨ë¦¬ íŒ¨í„´ê³¼ ê°™ì€ ê°€ë³€ ê¸¸ì´ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ ê³ ì • í¬ê¸°ë¡œ ë³€í™˜:

```python
preprocessor = MemoryPatternPaddingPreprocessor(
    max_tasks=None,  # ìë™ ê°ì§€
    max_memory_entries=None,  # ìë™ ê°ì§€
    padding_value=-999.0
)
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤! Pull Requestë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Issue Templates

í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì´ìŠˆ í…œí”Œë¦¿ì„ ì œê³µí•©ë‹ˆë‹¤:
- `âœ¨Feat` - ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
- `ğŸ›Fix` - ë²„ê·¸ ìˆ˜ì •

## ğŸ“§ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ë§í¬: [https://github.com/yourusername/rtems-ml-framework](https://github.com/yourusername/rtems-ml-framework)

## ğŸ”— ê´€ë ¨ í”„ë¡œì íŠ¸

- [RTEMS](https://www.rtems.org/) - Real-Time Executive for Multiprocessor Systems